<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>ifra API documentation</title>
<meta name="description" content="Interpretable Federated Rule Algorithm â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>ifra</code></h1>
</header>
<section id="section-intro">
<p>Interpretable Federated Rule Algorithm</p>
<p><strong>Federated Learning</strong> allows several sources (<em>nodes</em>) of data to contribute to a single model without sharing their
data between them. It thus answers the problematic of data confidentiality. All federated learning algorithm follow
those steps:</p>
<ol>
<li>
<p>Choosing a model to train</p>
</li>
<li>
<p>Having each node training its own model</p>
</li>
<li>
<p>Aggregate the models into a single one and share it with the nodes</p>
</li>
<li>
<p>Nodes produce a new model taking the central model into account for their next learning phase. In addition, in IFRA
the node will also produce a new model if its data is uptdated.</p>
</li>
</ol>
<p>Steps 2 to 4 are an 'iteration' of the learning and are repeated until either the user stops the algorithm or some
threshold is reached. In IFRA, no thresholds exist, and the learning stops when the user(s) decide so.</p>
<p>Differential privacy is automatically applied in each node by slightly changing the prediction of the rules
(Only working for regression rule for now).</p>
<p>IFRA consists of 3 independent and asynchronous actors, represented by the abstract class <code><a title="ifra.actor.Actor" href="actor.html#ifra.actor.Actor">Actor</a></code>.
Each can be run individually and monitors changes in its inputs. The three actors are :</p>
<ul>
<li>Nodes (<strong>inputs</strong>: data, central model, <strong>output</strong>: node model) (<code><a title="ifra.node.Node" href="node.html#ifra.node.Node">Node</a></code>)</li>
<li>Aggregator (<strong>input</strong>: node models, <strong>output</strong>: aggregated model) (<code><a title="ifra.aggregator.Aggregator" href="aggregator.html#ifra.aggregator.Aggregator">Aggregator</a></code>)</li>
<li>Central Server (<strong>input</strong>: aggregated model, <strong>output</strong>: central model) (<code><a title="ifra.central_server.CentralServer" href="central_server.html#ifra.central_server.CentralServer">CentralServer</a></code>)</li>
</ul>
<p>This architecture is bug resilient, since if a node is down it can just be restarted without impacting the other actors.
The difference between 'aggregated model' and 'central model' is that the central model will remember all the rules
learned from all previous iterations, while the aggregated model only know the rules of the current iteration.</p>
<p>In IFRA, nodes are anonymous : they all write their model to the same directory that is monitored by the aggregator, and
the aggregator does not have access to any information about the node. It does not know which node produced which model.</p>
<p>In IFRA, one node produces one ruleskit.RuleSet object. Each user is free to define its own model by
overloading the <code><a title="ifra.fitters.Fitter" href="fitters.html#ifra.fitters.Fitter">Fitter</a></code> class, as long as it produces a ruleskit.RuleSet object.
The available models currently are:</p>
<ul>
<li>
<p>decisiontreeregression (see <code><a title="ifra.fitters.DecisionTreeRegressionFitter" href="fitters.html#ifra.fitters.DecisionTreeRegressionFitter">DecisionTreeRegressionFitter</a></code> for details)</p>
</li>
<li>
<p>decisiontreeclassification (see <code><a title="ifra.fitters.DecisionTreeClassificationFitter" href="fitters.html#ifra.fitters.DecisionTreeClassificationFitter">DecisionTreeClassificationFitter</a></code> for details)</p>
</li>
</ul>
<p>The user also has the liberty to define its own aggregation method, by overloading <code>ifra.aggregation.Aggregation</code>.
The available aggregation methods currently are:</p>
<ul>
<li>
<p>adaboost (see <code><a title="ifra.aggregations.AdaBoostAggregation" href="aggregations.html#ifra.aggregations.AdaBoostAggregation">AdaBoostAggregation</a></code> for details)</p>
</li>
<li>
<p>reverseadaboost (see <code><a title="ifra.aggregations.ReverseAdaBoostAggregation" href="aggregations.html#ifra.aggregations.ReverseAdaBoostAggregation">ReverseAdaBoostAggregation</a></code> for details)</p>
</li>
<li>
<p>keepall (see <code><a title="ifra.aggregations.AggregateAll" href="aggregations.html#ifra.aggregations.AggregateAll">AggregateAll</a></code>)</p>
</li>
</ul>
<p>The user can implement the update method to be used by the node to take the central model into account by overloading
the <code><a title="ifra.node_model_updaters.NodeModelUpdater" href="node_model_updaters.html#ifra.node_model_updaters.NodeModelUpdater">NodeModelUpdater</a></code>. The available node updaters currently are:</p>
<ul>
<li>adaboost (adapted for adaboost, reverseadaboost and keepall aggregations)
(see <code><a title="ifra.node_model_updaters.AdaBoostNodeModelUpdater" href="node_model_updaters.html#ifra.node_model_updaters.AdaBoostNodeModelUpdater">AdaBoostNodeModelUpdater</a></code>)</li>
</ul>
<p>Each node has the possbility to execute a dataprep before the first learning. The user has the liberty to define its
dataprep method by overloading the <code><a title="ifra.datapreps.DataPrep" href="datapreps.html#ifra.datapreps.DataPrep">DataPrep</a></code> class. The available datapreps currently are:</p>
<ul>
<li>binfeatures (see <code><a title="ifra.datapreps.BinFeaturesDataPrep" href="datapreps.html#ifra.datapreps.BinFeaturesDataPrep">BinFeaturesDataPrep</a></code>)</li>
</ul>
<p>To overload a class, read its documentation. Then, to make the actors use your class specify them in the
actor's configuration file (<code>ifra.config.NodeLearningConfig</code> for <em>fitter</em>, <em>node updater</em> and <em>dataprep</em>) or in
<code>ifra.config.AggregatorConfig</code> json file for <em>aggregation</em>).</p>
<p>To be correctly imported, the line passed in the json for, let's say, the aggregation, must be like</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; {
&gt;&gt;&gt;    ...
&gt;&gt;&gt;    &quot;aggregation&quot;: &quot;some.importable.AggregationClass&quot;
&gt;&gt;&gt;    ...
&gt;&gt;&gt; }
where *some.importable.AggregationClass* can be imported from the current working directory.
</code></pre>
<p>To preserve data separation, each actor should be ran on a different machine. Models are shared across actors through
Google Cloud Storage, and it is the reponsability of the user to define buckets to store the models the the appropriate
I/O rights for each actors.</p>
<ul>
<li>Each node should have read access the one unique bucket where the central model is to be written. In addition, each
node should have a read access its own data. No other actor should have read access to them. It should also have
write access to a place where the nodes models will be written. The place must be identical for each node of a
given learning.</li>
<li>The aggregator should have read access to the place where nodes are expected to write their models, and write
access to a place dedicated for the aggregated model</li>
<li>The central server should have read access to the aggregated model, and write access to the place where the central
model is read by the nodes.</li>
</ul>
<p>GCS paths are handeled by transparentpath.TransparentPath objects. For testing purposes, those paths can be local if no
global filesystem is set by transparentpath.TransparentPath.</p>
<p>To use IFRA, you need to do 5 things:</p>
<ol>
<li>
<p>Define the nodes learning configurations in json files. It should be stored on GCS with read access by the node
only (set the appropriate access to the service accounts). See <code><a title="ifra.configs.NodeLearningConfig" href="configs.html#ifra.configs.NodeLearningConfig">NodeLearningConfig</a></code> for more
information.</p>
</li>
<li>
<p>Define the nodes data configurations in json files. It should be reachable by the node only.
See <code><a title="ifra.configs.NodeDataConfig" href="configs.html#ifra.configs.NodeDataConfig">NodeDataConfig</a></code> for more information.</p>
</li>
<li>
<p>Define the aggregator configuration in a json file. This file needs to be reachable by the aggregator only.
see <code><a title="ifra.configs.AggregatorConfig" href="configs.html#ifra.configs.AggregatorConfig">AggregatorConfig</a></code> for more information.</p>
</li>
<li>
<p>Define the central server configuration in a json file. This file needs to be reachable by the central server only.
see <code><a title="ifra.configs.CentralConfig" href="configs.html#ifra.configs.CentralConfig">CentralConfig</a></code> for more information.</p>
</li>
<li>
<p>On each node machine, instantiate the <code><a title="ifra.node.Node" href="node.html#ifra.node.Node">Node</a></code> class by providing it with its learning and
data configuration, and call the <code><a title="ifra.node.Node.run" href="node.html#ifra.node.Node.run">Node.run()</a></code> method.</p>
</li>
<li>On the machine that should act as the aggregator, instantiate the <code><a title="ifra.aggregator.Aggregator" href="aggregator.html#ifra.aggregator.Aggregator">Aggregator</a></code> class by
providing it with the list of all nodes configuration and its aggregator configuration, then call its
<code><a title="ifra.aggregator.Aggregator.run" href="aggregator.html#ifra.aggregator.Aggregator.run">Aggregator.run()</a></code> method.</li>
<li>On the machine that should act as the central server, instantiate the <code><a title="ifra.central_server.CentralServer" href="central_server.html#ifra.central_server.CentralServer">CentralServer</a></code> class by
providing it with the its central configuration, then call its <code><a title="ifra.central_server.CentralServer.run" href="central_server.html#ifra.central_server.CentralServer.run">CentralServer.run()</a></code> method.</li>
</ol>
<p>Step 5, 6 and 7 can be done in any order.</p>
<p>Example of step 1: you could create nodes learning configuration json files contaning.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; {
&gt;&gt;&gt;     &quot;features_names&quot;: [&quot;sepal length in cm&quot;, &quot;sepal width in cm&quot;, &quot;petal length in cm&quot;, &quot;petal width in cm&quot;],
&gt;&gt;&gt;     &quot;classes_names&quot;: [&quot;Iris-setosa&quot;, &quot;Iris-versicolor&quot;, &quot;Iris-virginica&quot;],  # Use an empty list if using regression
&gt;&gt;&gt;     &quot;x_mins&quot;: &quot;&quot;,
&gt;&gt;&gt;     &quot;x_maxs&quot;: &quot;&quot;,
&gt;&gt;&gt;     &quot;max_depth&quot;: 3,
&gt;&gt;&gt;     &quot;plot_data&quot;: true,
&gt;&gt;&gt;     &quot;get_leaf&quot;: false,
&gt;&gt;&gt;     &quot;node_models_path&quot;: &quot;gs://bucket_node_models&quot;,
&gt;&gt;&gt;     &quot;node_models_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;central_model_path&quot;: &quot;gs://bucket_central_server/ruleset.csv&quot;,
&gt;&gt;&gt;     &quot;central_model_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;id&quot;: &quot;node_name&quot;,
&gt;&gt;&gt;     &quot;dataprep&quot;: &quot;binfeatures&quot;,
&gt;&gt;&gt;     &quot;dataprep_kwargs&quot;: {&quot;nbins&quot;: 5, &quot;bins&quot;: {}, &quot;save_bins&quot;: &quot;gs://bucket_node_0/bins.json&quot;},
&gt;&gt;&gt;     &quot;fitter&quot;: &quot;decisiontreeclassification&quot;,
&gt;&gt;&gt;     &quot;fitter_kwargs&quot;: {},
&gt;&gt;&gt;     &quot;updater&quot;: &quot;adaboost&quot;,
&gt;&gt;&gt;     &quot;updater_kwargs&quot;: {},
&gt;&gt;&gt;     &quot;train_test_split&quot;: &quot;&quot;,
&gt;&gt;&gt;     &quot;thresholds_path&quot;: &quot;gs://bucket_node_0/thresholds.json&quot;,
&gt;&gt;&gt;     &quot;thresholds_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;emitter_path&quot;: &quot;gs://bucket_node_0_messages/node_chien_messages.json&quot;,
&gt;&gt;&gt;     &quot;emitter_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;eval_kwargs&quot;: {&quot;criterion_method&quot;: &quot;success_rate&quot;},
&gt;&gt;&gt;     &quot;privacy_proba&quot;: 0.3
&gt;&gt;&gt; }
</code></pre>
<p>See <code><a title="ifra.configs.NodeLearningConfig" href="configs.html#ifra.configs.NodeLearningConfig">NodeLearningConfig</a></code> for information about those configurations.</p>
<p>Example of step 2: you could create nodes data configuration json files contaning:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; {
&gt;&gt;&gt;   &quot;x_path&quot;: &quot;gs://bucket_node_0/x.csv&quot;,
&gt;&gt;&gt;   &quot;y_path&quot;: &quot;gs://bucket_node_0/y.csv&quot;,
&gt;&gt;&gt;   &quot;x_read_kwargs&quot;: {&quot;index_col&quot;: 0},
&gt;&gt;&gt;   &quot;y_read_kwargs&quot;: {&quot;index_col&quot;: 0},
&gt;&gt;&gt;   &quot;x_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;   &quot;y_path_fs&quot;: &quot;gcs&quot;
&gt;&gt;&gt; }
</code></pre>
<p>See <code><a title="ifra.configs.NodeDataConfig" href="configs.html#ifra.configs.NodeDataConfig">NodeDataConfig</a></code> for information about those configurations.</p>
<p>Example of step 3: you could create a aggragator configuration json file contaning:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; {
&gt;&gt;&gt;     &quot;node_models_path&quot;: &quot;gs://bucket_node_models&quot;,
&gt;&gt;&gt;     &quot;node_models_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;aggregated_model_path&quot;: &quot;gs://bucket_aggregated_model/ruleset.csv&quot;,
&gt;&gt;&gt;     &quot;aggregated_model_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;emitter_path&quot;: &quot;gs://bucket_aggregator_messages/aggregator_messages.json&quot;,
&gt;&gt;&gt;     &quot;emitter_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;min_number_of_new_models&quot;: 2,
&gt;&gt;&gt;     &quot;aggregation&quot;: &quot;adaboost&quot;,
&gt;&gt;&gt;     &quot;aggregation_kwargs&quot;: {},
&gt;&gt;&gt;     &quot;weight&quot;: &quot;&quot;,
&gt;&gt;&gt;     &quot;best&quot;: &quot;&quot;
&gt;&gt;&gt; }
</code></pre>
<p>See <code>ifra.configs.AggretatorConfig</code> for information about those configurations.</p>
<p>Example of step 4: you could create a central server configuration json file contaning:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; {
&gt;&gt;&gt;     &quot;central_model_path&quot;: &quot;gs://bucket_central_model/ruleset.csv&quot;,
&gt;&gt;&gt;     &quot;central_model_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;aggregated_model_path&quot;: &quot;gs://bucket_aggregated_model/ruleset.csv&quot;,
&gt;&gt;&gt;     &quot;aggregated_model_path_fs&quot;: &quot;gcs&quot;,
&gt;&gt;&gt;     &quot;emitter_path&quot;: &quot;gs://bucket_central_messages/central_messages.json&quot;,
&gt;&gt;&gt;     &quot;emitter_path_fs&quot;: &quot;local&quot;
&gt;&gt;&gt; }
</code></pre>
<p>See <code><a title="ifra.configs.CentralConfig" href="configs.html#ifra.configs.CentralConfig">CentralConfig</a></code> for information about those configurations.</p>
<p>Example of step 5:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; from ifra import Node, NodeLearningConfig, NodeDataConfig
&gt;&gt;&gt; from transparentpath import Path
&gt;&gt;&gt; learning_config_path = NodeLearningConfig(Path(&quot;gs://bucket_node_learning_configs/learning_configs_0.json&quot;))
&gt;&gt;&gt; data_config_path = NodeDataConfig(Path(&quot;data_configs.json&quot;, fs=&quot;local&quot;))
&gt;&gt;&gt; thenode = Node(learning_configs=path_learning, data=path_data)
&gt;&gt;&gt; thenode.run()
</code></pre>
<p>Example of step 6:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; from ifra import Aggregator, NodeLearningConfig, AggregatorConfig
&gt;&gt;&gt; nodes_learning_config = [
&gt;&gt;&gt;   NodeLearningConfig(Path(&quot;gs://bucket_node_learning_configs/learning_configs_0.json&quot;))
&gt;&gt;&gt;   NodeLearningConfig(Path(&quot;gs://bucket_node_learning_configs/learning_configs_1.json&quot;))
&gt;&gt;&gt;   NodeLearningConfig(Path(&quot;gs://bucket_node_learning_configs/learning_configs_2.json&quot;))
&gt;&gt;&gt;   NodeLearningConfig(Path(&quot;gs://bucket_node_learning_configs/learning_configs_3.json&quot;))
&gt;&gt;&gt; ]
&gt;&gt;&gt; aggregator_config = AggregatorConfig(Path(&quot;aggregator_configs.json&quot;, fs=&quot;local&quot;))
&gt;&gt;&gt; aggr = Aggregator(nodes_configs=nodes_learning_config, aggregator_configs=aggregator_config)
&gt;&gt;&gt; aggr.run()
</code></pre>
<p>Example of step 7:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; from ifra import CentralServer, CentralConfig
&gt;&gt;&gt; central_config = CentralConfig(Path(&quot;central_configs.json&quot;, fs=&quot;local&quot;))
&gt;&gt;&gt; server = CentralServer(central_configs=central_config)
&gt;&gt;&gt; server.run()
</code></pre>
<p>The 'emitter_path' configuration present for each actor will be used in a futur update to monitor what each actor is
doing.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># noinspection PyUnresolvedReferences
&#34;&#34;&#34;Interpretable Federated Rule Algorithm

**Federated Learning** allows several sources (*nodes*) of data to contribute to a single model without sharing their
data between them. It thus answers the problematic of data confidentiality. All federated learning algorithm follow
those steps:

  1. Choosing a model to train\n
  2. Having each node training its own model\n
  3. Aggregate the models into a single one and share it with the nodes\n
  4. Nodes produce a new model taking the central model into account for their next learning phase. In addition, in IFRA
  the node will also produce a new model if its data is uptdated.\n

Steps 2 to 4 are an &#39;iteration&#39; of the learning and are repeated until either the user stops the algorithm or some
threshold is reached. In IFRA, no thresholds exist, and the learning stops when the user(s) decide so.

Differential privacy is automatically applied in each node by slightly changing the prediction of the rules
(Only working for regression rule for now).

IFRA consists of 3 independent and asynchronous actors, represented by the abstract class `ifra.actor.Actor`.
Each can be run individually and monitors changes in its inputs. The three actors are :

  * Nodes (**inputs**: data, central model, **output**: node model) (`ifra.node.Node`)
  * Aggregator (**input**: node models, **output**: aggregated model) (`ifra.aggregator.Aggregator`)
  * Central Server (**input**: aggregated model, **output**: central model) (`ifra.central_server.CentralServer`)

This architecture is bug resilient, since if a node is down it can just be restarted without impacting the other actors.
The difference between &#39;aggregated model&#39; and &#39;central model&#39; is that the central model will remember all the rules
learned from all previous iterations, while the aggregated model only know the rules of the current iteration.

In IFRA, nodes are anonymous : they all write their model to the same directory that is monitored by the aggregator, and
the aggregator does not have access to any information about the node. It does not know which node produced which model.

In IFRA, one node produces one ruleskit.RuleSet object. Each user is free to define its own model by
overloading the `ifra.fitters.Fitter` class, as long as it produces a ruleskit.RuleSet object.
The available models currently are:

  * decisiontreeregression (see `ifra.fitters.DecisionTreeRegressionFitter` for details)\n
  * decisiontreeclassification (see `ifra.fitters.DecisionTreeClassificationFitter` for details)

The user also has the liberty to define its own aggregation method, by overloading `ifra.aggregation.Aggregation`.
The available aggregation methods currently are:

  * adaboost (see `ifra.aggregations.AdaBoostAggregation` for details)\n
  * reverseadaboost (see `ifra.aggregations.ReverseAdaBoostAggregation` for details)\n
  * keepall (see `ifra.aggregations.AggregateAll`)

The user can implement the update method to be used by the node to take the central model into account by overloading
the `ifra.node_model_updaters.NodeModelUpdater`. The available node updaters currently are:

  * adaboost (adapted for adaboost, reverseadaboost and keepall aggregations)
  (see `ifra.node_model_updaters.AdaBoostNodeModelUpdater`)

Each node has the possbility to execute a dataprep before the first learning. The user has the liberty to define its
dataprep method by overloading the `ifra.datapreps.DataPrep` class. The available datapreps currently are:

  * binfeatures (see `ifra.datapreps.BinFeaturesDataPrep`)

To overload a class, read its documentation. Then, to make the actors use your class specify them in the
actor&#39;s configuration file (`ifra.config.NodeLearningConfig` for *fitter*, *node updater* and *dataprep*) or in
`ifra.config.AggregatorConfig` json file for *aggregation*).

To be correctly imported, the line passed in the json for, let&#39;s say, the aggregation, must be like

&gt;&gt;&gt; {
&gt;&gt;&gt;    ...
&gt;&gt;&gt;    &#34;aggregation&#34;: &#34;some.importable.AggregationClass&#34;
&gt;&gt;&gt;    ...
&gt;&gt;&gt; }
where *some.importable.AggregationClass* can be imported from the current working directory.

To preserve data separation, each actor should be ran on a different machine. Models are shared across actors through
Google Cloud Storage, and it is the reponsability of the user to define buckets to store the models the the appropriate
I/O rights for each actors.

  * Each node should have read access the one unique bucket where the central model is to be written. In addition, each
    node should have a read access its own data. No other actor should have read access to them. It should also have
    write access to a place where the nodes models will be written. The place must be identical for each node of a
    given learning.
  * The aggregator should have read access to the place where nodes are expected to write their models, and write
    access to a place dedicated for the aggregated model
  * The central server should have read access to the aggregated model, and write access to the place where the central
    model is read by the nodes.

GCS paths are handeled by transparentpath.TransparentPath objects. For testing purposes, those paths can be local if no
global filesystem is set by transparentpath.TransparentPath.

To use IFRA, you need to do 5 things:

  1. Define the nodes learning configurations in json files. It should be stored on GCS with read access by the node
     only (set the appropriate access to the service accounts). See `ifra.configs.NodeLearningConfig` for more
     information.\n
  2. Define the nodes data configurations in json files. It should be reachable by the node only.
     See `ifra.configs.NodeDataConfig` for more information.\n
  3. Define the aggregator configuration in a json file. This file needs to be reachable by the aggregator only.
     see `ifra.configs.AggregatorConfig` for more information.\n
  4. Define the central server configuration in a json file. This file needs to be reachable by the central server only.
     see `ifra.configs.CentralConfig` for more information.\n
  5. On each node machine, instantiate the `ifra.node.Node` class by providing it with its learning and
     data configuration, and call the `ifra.node.Node.run` method.
  6. On the machine that should act as the aggregator, instantiate the `ifra.aggregator.Aggregator` class by
     providing it with the list of all nodes configuration and its aggregator configuration, then call its
     `ifra.aggregator.Aggregator.run` method.
  7. On the machine that should act as the central server, instantiate the `ifra.central_server.CentralServer` class by
     providing it with the its central configuration, then call its `ifra.central_server.CentralServer.run` method.

Step 5, 6 and 7 can be done in any order.

Example of step 1: you could create nodes learning configuration json files contaning.

&gt;&gt;&gt; {
&gt;&gt;&gt;     &#34;features_names&#34;: [&#34;sepal length in cm&#34;, &#34;sepal width in cm&#34;, &#34;petal length in cm&#34;, &#34;petal width in cm&#34;],
&gt;&gt;&gt;     &#34;classes_names&#34;: [&#34;Iris-setosa&#34;, &#34;Iris-versicolor&#34;, &#34;Iris-virginica&#34;],  # Use an empty list if using regression
&gt;&gt;&gt;     &#34;x_mins&#34;: &#34;&#34;,
&gt;&gt;&gt;     &#34;x_maxs&#34;: &#34;&#34;,
&gt;&gt;&gt;     &#34;max_depth&#34;: 3,
&gt;&gt;&gt;     &#34;plot_data&#34;: true,
&gt;&gt;&gt;     &#34;get_leaf&#34;: false,
&gt;&gt;&gt;     &#34;node_models_path&#34;: &#34;gs://bucket_node_models&#34;,
&gt;&gt;&gt;     &#34;node_models_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;central_model_path&#34;: &#34;gs://bucket_central_server/ruleset.csv&#34;,
&gt;&gt;&gt;     &#34;central_model_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;id&#34;: &#34;node_name&#34;,
&gt;&gt;&gt;     &#34;dataprep&#34;: &#34;binfeatures&#34;,
&gt;&gt;&gt;     &#34;dataprep_kwargs&#34;: {&#34;nbins&#34;: 5, &#34;bins&#34;: {}, &#34;save_bins&#34;: &#34;gs://bucket_node_0/bins.json&#34;},
&gt;&gt;&gt;     &#34;fitter&#34;: &#34;decisiontreeclassification&#34;,
&gt;&gt;&gt;     &#34;fitter_kwargs&#34;: {},
&gt;&gt;&gt;     &#34;updater&#34;: &#34;adaboost&#34;,
&gt;&gt;&gt;     &#34;updater_kwargs&#34;: {},
&gt;&gt;&gt;     &#34;train_test_split&#34;: &#34;&#34;,
&gt;&gt;&gt;     &#34;thresholds_path&#34;: &#34;gs://bucket_node_0/thresholds.json&#34;,
&gt;&gt;&gt;     &#34;thresholds_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;emitter_path&#34;: &#34;gs://bucket_node_0_messages/node_chien_messages.json&#34;,
&gt;&gt;&gt;     &#34;emitter_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;eval_kwargs&#34;: {&#34;criterion_method&#34;: &#34;success_rate&#34;},
&gt;&gt;&gt;     &#34;privacy_proba&#34;: 0.3
&gt;&gt;&gt; }

See `ifra.configs.NodeLearningConfig` for information about those configurations.


Example of step 2: you could create nodes data configuration json files contaning:

&gt;&gt;&gt; {
&gt;&gt;&gt;   &#34;x_path&#34;: &#34;gs://bucket_node_0/x.csv&#34;,
&gt;&gt;&gt;   &#34;y_path&#34;: &#34;gs://bucket_node_0/y.csv&#34;,
&gt;&gt;&gt;   &#34;x_read_kwargs&#34;: {&#34;index_col&#34;: 0},
&gt;&gt;&gt;   &#34;y_read_kwargs&#34;: {&#34;index_col&#34;: 0},
&gt;&gt;&gt;   &#34;x_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;   &#34;y_path_fs&#34;: &#34;gcs&#34;
&gt;&gt;&gt; }

See `ifra.configs.NodeDataConfig` for information about those configurations.

Example of step 3: you could create a aggragator configuration json file contaning:

&gt;&gt;&gt; {
&gt;&gt;&gt;     &#34;node_models_path&#34;: &#34;gs://bucket_node_models&#34;,
&gt;&gt;&gt;     &#34;node_models_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;aggregated_model_path&#34;: &#34;gs://bucket_aggregated_model/ruleset.csv&#34;,
&gt;&gt;&gt;     &#34;aggregated_model_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;emitter_path&#34;: &#34;gs://bucket_aggregator_messages/aggregator_messages.json&#34;,
&gt;&gt;&gt;     &#34;emitter_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;min_number_of_new_models&#34;: 2,
&gt;&gt;&gt;     &#34;aggregation&#34;: &#34;adaboost&#34;,
&gt;&gt;&gt;     &#34;aggregation_kwargs&#34;: {},
&gt;&gt;&gt;     &#34;weight&#34;: &#34;&#34;,
&gt;&gt;&gt;     &#34;best&#34;: &#34;&#34;
&gt;&gt;&gt; }

See `ifra.configs.AggretatorConfig` for information about those configurations.

Example of step 4: you could create a central server configuration json file contaning:

&gt;&gt;&gt; {
&gt;&gt;&gt;     &#34;central_model_path&#34;: &#34;gs://bucket_central_model/ruleset.csv&#34;,
&gt;&gt;&gt;     &#34;central_model_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;aggregated_model_path&#34;: &#34;gs://bucket_aggregated_model/ruleset.csv&#34;,
&gt;&gt;&gt;     &#34;aggregated_model_path_fs&#34;: &#34;gcs&#34;,
&gt;&gt;&gt;     &#34;emitter_path&#34;: &#34;gs://bucket_central_messages/central_messages.json&#34;,
&gt;&gt;&gt;     &#34;emitter_path_fs&#34;: &#34;local&#34;
&gt;&gt;&gt; }

See `ifra.configs.CentralConfig` for information about those configurations.

Example of step 5:

&gt;&gt;&gt; from ifra import Node, NodeLearningConfig, NodeDataConfig
&gt;&gt;&gt; from transparentpath import Path
&gt;&gt;&gt; learning_config_path = NodeLearningConfig(Path(&#34;gs://bucket_node_learning_configs/learning_configs_0.json&#34;))
&gt;&gt;&gt; data_config_path = NodeDataConfig(Path(&#34;data_configs.json&#34;, fs=&#34;local&#34;))
&gt;&gt;&gt; thenode = Node(learning_configs=path_learning, data=path_data)
&gt;&gt;&gt; thenode.run()

Example of step 6:

&gt;&gt;&gt; from ifra import Aggregator, NodeLearningConfig, AggregatorConfig
&gt;&gt;&gt; nodes_learning_config = [
&gt;&gt;&gt;   NodeLearningConfig(Path(&#34;gs://bucket_node_learning_configs/learning_configs_0.json&#34;))
&gt;&gt;&gt;   NodeLearningConfig(Path(&#34;gs://bucket_node_learning_configs/learning_configs_1.json&#34;))
&gt;&gt;&gt;   NodeLearningConfig(Path(&#34;gs://bucket_node_learning_configs/learning_configs_2.json&#34;))
&gt;&gt;&gt;   NodeLearningConfig(Path(&#34;gs://bucket_node_learning_configs/learning_configs_3.json&#34;))
&gt;&gt;&gt; ]
&gt;&gt;&gt; aggregator_config = AggregatorConfig(Path(&#34;aggregator_configs.json&#34;, fs=&#34;local&#34;))
&gt;&gt;&gt; aggr = Aggregator(nodes_configs=nodes_learning_config, aggregator_configs=aggregator_config)
&gt;&gt;&gt; aggr.run()

Example of step 7:

&gt;&gt;&gt; from ifra import CentralServer, CentralConfig
&gt;&gt;&gt; central_config = CentralConfig(Path(&#34;central_configs.json&#34;, fs=&#34;local&#34;))
&gt;&gt;&gt; server = CentralServer(central_configs=central_config)
&gt;&gt;&gt; server.run()

The &#39;emitter_path&#39; configuration present for each actor will be used in a futur update to monitor what each actor is
doing.
&#34;&#34;&#34;

from .node import Node
from .central_server import CentralServer
from .aggregator import Aggregator
from .datapreps import DataPrep
from .node_model_updaters import NodeModelUpdater
from .fitters import Fitter
from .aggregations import Aggregation
from .setup_logger import setup_logger
from .configs import AggregatorConfig, CentralConfig, NodeLearningConfig, NodeDataConfig


from . import _version
__version__ = _version.get_versions()[&#39;version&#39;]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="ifra.actor" href="actor.html">ifra.actor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.aggregations" href="aggregations.html">ifra.aggregations</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.aggregator" href="aggregator.html">ifra.aggregator</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.central_server" href="central_server.html">ifra.central_server</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.configs" href="configs.html">ifra.configs</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.datapreps" href="datapreps.html">ifra.datapreps</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.decorator" href="decorator.html">ifra.decorator</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.diff_privacy" href="diff_privacy.html">ifra.diff_privacy</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.duplicated_rules_updater" href="duplicated_rules_updater.html">ifra.duplicated_rules_updater</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.fitters" href="fitters.html">ifra.fitters</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.loader" href="loader.html">ifra.loader</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.messenger" href="messenger.html">ifra.messenger</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.node" href="node.html">ifra.node</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.node_model_updaters" href="node_model_updaters.html">ifra.node_model_updaters</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.plot" href="plot.html">ifra.plot</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.setup_logger" href="setup_logger.html">ifra.setup_logger</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ifra.train_test_split" href="train_test_split.html">ifra.train_test_split</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="ifra.actor" href="actor.html">ifra.actor</a></code></li>
<li><code><a title="ifra.aggregations" href="aggregations.html">ifra.aggregations</a></code></li>
<li><code><a title="ifra.aggregator" href="aggregator.html">ifra.aggregator</a></code></li>
<li><code><a title="ifra.central_server" href="central_server.html">ifra.central_server</a></code></li>
<li><code><a title="ifra.configs" href="configs.html">ifra.configs</a></code></li>
<li><code><a title="ifra.datapreps" href="datapreps.html">ifra.datapreps</a></code></li>
<li><code><a title="ifra.decorator" href="decorator.html">ifra.decorator</a></code></li>
<li><code><a title="ifra.diff_privacy" href="diff_privacy.html">ifra.diff_privacy</a></code></li>
<li><code><a title="ifra.duplicated_rules_updater" href="duplicated_rules_updater.html">ifra.duplicated_rules_updater</a></code></li>
<li><code><a title="ifra.fitters" href="fitters.html">ifra.fitters</a></code></li>
<li><code><a title="ifra.loader" href="loader.html">ifra.loader</a></code></li>
<li><code><a title="ifra.messenger" href="messenger.html">ifra.messenger</a></code></li>
<li><code><a title="ifra.node" href="node.html">ifra.node</a></code></li>
<li><code><a title="ifra.node_model_updaters" href="node_model_updaters.html">ifra.node_model_updaters</a></code></li>
<li><code><a title="ifra.plot" href="plot.html">ifra.plot</a></code></li>
<li><code><a title="ifra.setup_logger" href="setup_logger.html">ifra.setup_logger</a></code></li>
<li><code><a title="ifra.train_test_split" href="train_test_split.html">ifra.train_test_split</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>